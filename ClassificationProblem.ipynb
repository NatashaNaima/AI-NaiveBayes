{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1520c40-d478-4bdb-b153-05f983d9f25f",
   "metadata": {},
   "source": [
    "# **ASSIGNMENT 2 - EMPIRICAL STUDY OF CLASSIFICATION PROBLEM**\n",
    "\n",
    "# 1. Group Description\n",
    "Group Number:[add this later] <br>\n",
    "Names: Natasha Hussain | Daanish Khan <br>\n",
    "Student Numbers: 300122562 | 300126840 <br>\n",
    "\n",
    "# 2. The Classification Problem\n",
    "[WRITE A DESCRIPTION]\n",
    "\n",
    "# 3. The Dataset\n",
    "In this assignment, we used WineQT.csv from : https://www.kaggle.com/datasets/yasserh/wine-quality-dataset\n",
    "This dataset of wine samples has :\n",
    "Number of samples: 4898, Number of attributes: 11, Number of classes: 11 (0 to 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "874808a8-55ae-4e4e-9271-3cf2e083a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries we will use throughout the assignment\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "#importing the wine quality dataset\n",
    "url = 'https://raw.githubusercontent.com/NatashaNaima/AI-NaiveBayes/main/WineQT.csv'\n",
    "dataset = pd.read_csv(url)\n",
    "\n",
    "dataset.columns\n",
    "# a small set to reduce literal runtime while testing\n",
    "small_set = dataset.head(10)\n",
    "\n",
    "# Turning each column of our table into an array for ease of access\n",
    "fixed_acidity = dataset['fixed acidity'].tolist()\n",
    "volatile_acidity = dataset['volatile acidity'].tolist()\n",
    "citric_acid = dataset['citric acid'].tolist()\n",
    "residual_sugar = dataset['residual sugar'].tolist()\n",
    "chlorides = dataset['chlorides'].tolist()\n",
    "free_sulfur_dioxide = dataset['free sulfur dioxide'].tolist()\n",
    "total_sulfur_dioxide = dataset['total sulfur dioxide'].tolist()\n",
    "density = dataset['density'].tolist()\n",
    "pH = dataset['pH'].tolist()\n",
    "sulphates = dataset['sulphates'].tolist()\n",
    "alcohol = dataset['alcohol'].tolist()\n",
    "quality = dataset['quality'].tolist()\n",
    "Id = dataset['Id'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54de625-0fb9-4086-afd6-5f40478bbedf",
   "metadata": {},
   "source": [
    "[More Questions on the dataset that would use the arrays]\n",
    "Think about the features that could be useful for this task, are they all present in the\n",
    "dataset? Anything missing? Any feature provided that doesnâ€™t seem useful to you?\n",
    "Do you have the domain expertise to answer these questions? If you don't, think of\n",
    "ways to explore the attributes to establish whether they appear to influence the\n",
    "classification.\n",
    "\n",
    "The most important feature provided in our dataset is the 'quality' column. It is in accordance with this feature that we will classify the entries of our dataset and evaluate 'new' entries to our dataset. We are also provided, alongside ID which differentiates each entry, many other quantative entries about particular physical properties of each wine. We are not wine tasters nor manufacterers nor any specialist or enthusiasts about wine, so we do not entirely understand the relevancy of each of these features. With this in mind however, by the end of this assignment we hope to establish some trends and therefore influences of each of these features as to how they affect wine quality.\n",
    "\n",
    "b. What are the ranges of each feature? Try to compare and visualize those ranges. We\n",
    "discussed in class that attribute normalisation is often promoted as empirically\n",
    "helping to improve performances. Do you think this would be useful for your study?\n",
    "Quality : Ranges from 3 to 8 where each entry is a whole number\n",
    "Alcohol : Ranges from 8.4 to 14.9 where each entry is a percentage to 1 significant digit (ex.12.3%)\n",
    "Sulfates : Ranges from 0.33 to 2 where each entry is 2 significant digits (ex.1.23)\n",
    "pH : Ranges from 2.74 to 4.01 where each entry is 2 significant digits (ex.3.22)\n",
    "density : Ranges from 0.99 to 1 where each entry is at least 4 significant digits (ex.0.9902)\n",
    "total sulfur dioxide : Ranges from 6 to 289 where every entry is a whole number\n",
    "free sulfur : Ranges from 1 to 68 where each entry is a whole number\n",
    "chloride : Ranges from 0.01 to 0.61 where each entry is at least 2 significant digits (ex. 0.07)\n",
    "residual sugar : Ranges from 0.9 to 15.5 where each entry is 1 significant digit (ex 8.6)\n",
    "citric acid : Ranges from 0 to 1 where each entry has 2 significant digits ( ex 0.27)\n",
    "volatile acidity : Ranges from 0.12 to 1.58 where each entry has at least 2 significant digits\n",
    "fixed acidity : Ranges from 4.6 to 15.9 where each entry has 1 significant digits (ex. 9.6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe5ebe-15b5-47bb-9384-1944ee1d7229",
   "metadata": {},
   "source": [
    "# 4. Encoding the features\n",
    "[As you will use models that need discrete or continuous attributes, think about data\n",
    "encoding and transformation.]\n",
    "\n",
    "## Encoding for Logistical Regression\n",
    "Since all of our entries are numbers on a continuous scale, we do not need to encode them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4794df8e-3283-4c1d-a243-856932f46194",
   "metadata": {},
   "source": [
    "## Encoding for Naive Bayes\n",
    "We saw in class that this classifier expects discrete attributes. But in scikit-\n",
    "learn, there are several types of Naive Bayes classifiers, such as\n",
    "CategoricalNB and GaussianNB. The CategoricalNB matches what we saw in\n",
    "class (and includes an additional smoothing factor). But there is also\n",
    "GaussianNB which assumes a Gaussian distribution on continuous attributes.\n",
    "Choose one of the two classifiers according to your data. You can also test\n",
    "both (optional). [Make decision and change description accordingly] (We can probably go with Gaussian since our dataset is continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efe84be-67a8-444f-8880-50caa962b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is generally how we will need to describe in code the dataset when we do Naive Bayes. I think it is the same for the other one\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_features=6,\n",
    "    n_classes=3,\n",
    "    n_samples=800,\n",
    "    n_informative=2,\n",
    "    random_state=1,\n",
    "    n_clusters_per_class=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9038f6f9-377b-4fcf-80ed-0fba37ab27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code block for Naive Bayes encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5858705-4ba0-4614-9f6c-1d3ba844a670",
   "metadata": {},
   "source": [
    "# 5. Defining Logistical Regression and Naive-Bayes Model\n",
    "\n",
    "## Logistical Regression\n",
    "[write some description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128b5ebe-4762-4c69-bc3f-70cb98117721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code block for logistical regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2ebd2f-8055-4b5f-bfab-55bbe0b9ca3a",
   "metadata": {},
   "source": [
    "## Naive-Bayes\n",
    "[Write some description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051a9e0-105b-48c6-83a2-701308136631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Block for Naive-Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc22f935-5976-4284-af44-ee359c9220c2",
   "metadata": {},
   "source": [
    "# 6. Evaluating our Models\n",
    "\n",
    "## 4-fold cross validation\n",
    "We will use 4-fold cross validation to evaluate our models. [write short description of 4-fold cross]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e241222-247a-4b4c-8329-68e54273b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Block for 4-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f1767a-2375-4458-9009-39d917bd1373",
   "metadata": {},
   "source": [
    "## Performing evaluation with precision/recall measures\n",
    "[Perform an evaluation with precision/recall measures. Since you are looking at a\n",
    "multi-class problem, make sure that you compare micro and macro averages on\n",
    "precision and recall]\n",
    "[Make sure to note parameters used in here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0823e86-c2d2-455d-bf53-17b5e4e19b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code block for using 4-fold cross validation on naive bayes and log.rg."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d794987b-f7c5-4b1f-b8b5-02b18b74e8aa",
   "metadata": {},
   "source": [
    "# 7. Modifying Parameters\n",
    "[State what parameters are modified in the following code cells.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a193c46d-81ed-4cc0-91bd-24bb82d6e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell for first log.reg. call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458af772-05e5-4934-9536-463eac978f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell for second log.reg. call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50297a01-6bd3-4488-97f9-e8535656be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell for first naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ceee22-7df9-479b-95e0-dbf215754c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code cell for second naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39529cc5-9a4a-4317-9d90-97059c18272a",
   "metadata": {},
   "source": [
    "# 8. Analysis\n",
    "[Compare quantitatively (with the precision/recall measures) your 6 results. Your 6\n",
    "results should use the same cross-validation technique (same k). The 6 results come\n",
    "from 2 models, each with default parameters from step 5 + 2 variations from step 6.\n",
    "Make sure to show your tests in cells. If you change a parameter, create a new cell\n",
    "and test. If you are making graphs for visualization, the values should not be\n",
    "\"hardcoded\".]\n",
    "\n",
    "[b. As was mentioned before, since you are looking at a multi-class problem, make sure\n",
    "that you compare with micro and macro averages on precision and recall. Discuss\n",
    "the differences (if any) obtained]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf8ce9a-a3c2-40f3-80d9-977fefc5d349",
   "metadata": {},
   "source": [
    "# 9. References:\n",
    "1. https://www.datacamp.com/tutorial/naive-bayes-scikit-learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
